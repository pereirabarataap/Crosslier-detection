{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy as copy\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neighbors import KernelDensity as KDE\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_tons(df):\n",
    "    id_tons = {}\n",
    "    ids = copy(df[\"id\"].unique())\n",
    "    for idd in ids:\n",
    "        id_loc = copy(df[\"id\"]==idd)\n",
    "        agg_tons = copy(df.loc[id_loc, \"ton\"].values.tolist())\n",
    "        id_tons[idd] = copy(agg_tons)\n",
    "    return copy(id_tons)\n",
    "def get_id_dates(df):\n",
    "    id_dates = {} # date_shift values are stored per {id: [v,a,l,u,e,s]}\n",
    "    ids = copy(df[\"id\"].unique())\n",
    "    for idd in ids:\n",
    "        id_loc = copy(df[\"id\"]==idd)\n",
    "        pre_agg_dates = copy(df.loc[id_loc, [\"date\"]].sort_values(by=\"date\"))\n",
    "        agg_dates = copy((pre_agg_dates - pre_agg_dates.shift())[\"date\"].dt.days[1:].astype(int).tolist())\n",
    "        id_dates[idd] = copy(agg_dates)\n",
    "    return copy(id_dates)\n",
    "def get_ton_bins(df):\n",
    "    tons = copy(sorted(df[\"ton\"]))\n",
    "    ton_bins = copy(pd.qcut(tons, q=10))\n",
    "    ton_intervals = copy([pd.Interval(-np.inf, ton_bins.categories[0].right)])\n",
    "    ton_intervals += copy([ton_bins.categories[i] for i in range(1, len(ton_bins.categories)-1)])\n",
    "    ton_intervals += copy([pd.Interval(ton_bins.categories[-1].left, np.inf)])\n",
    "    ton_bins = copy(pd.IntervalIndex(ton_intervals))\n",
    "    ton_bins = copy(pd.core.arrays.categorical.Categorical(ton_bins))\n",
    "    return copy(ton_bins)\n",
    "def get_date_bins(df):\n",
    "\n",
    "    def get_dates(df):\n",
    "        dates = []\n",
    "        ids = copy(df[\"id\"].unique())\n",
    "        for idd in ids:\n",
    "            id_loc = copy(df[\"id\"]==idd)\n",
    "            pre_agg_dates = copy(df.loc[id_loc, [\"date\"]].sort_values(by=\"date\"))\n",
    "            agg_dates = copy((pre_agg_dates - pre_agg_dates.shift())[\"date\"].dt.days[1:].astype(int).tolist())\n",
    "            dates += copy(agg_dates)\n",
    "        return copy(dates)\n",
    "\n",
    "    dates = copy(sorted(get_dates(df)))\n",
    "    ind = 0\n",
    "    tent = 0\n",
    "    success = 0\n",
    "    date_intervals = []\n",
    "    while not success:\n",
    "        try:\n",
    "            qcuts = copy(pd.qcut(dates[ind:], q=10-tent))\n",
    "            success=1\n",
    "        except:\n",
    "            date_intervals += copy([pd.Interval(tent-1, tent)])\n",
    "            ind += copy(pd.value_counts(dates)[tent])\n",
    "            tent+=1\n",
    "    date_intervals += copy([qcuts.categories[i] for i in range(len(qcuts.categories))])\n",
    "    date_intervals[0] = copy(pd.Interval(-np.inf, date_intervals[0].right))\n",
    "    date_intervals[-1] = copy(pd.Interval(date_intervals[-1].left, np.inf))\n",
    "    date_bins = copy(pd.IntervalIndex(date_intervals))\n",
    "    date_bins = copy(pd.core.arrays.categorical.Categorical(date_bins))\n",
    "    return copy(date_bins)\n",
    "def get_cv_df(label_cv_dfs):\n",
    "    for label_cv_df in label_cv_dfs:\n",
    "        try:\n",
    "            cv_df = pd.concat(\n",
    "                (\n",
    "                    cv_df,\n",
    "                    label_cv_df\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            cv_df = copy(label_cv_df)\n",
    "\n",
    "    columns = cv_df.columns.tolist()\n",
    "    tests = [column for column in columns if (\"test\" in column)]\n",
    "    trains = [column for column in columns if (\"train\" in column)]\n",
    "\n",
    "    test_df = cv_df[tests]\n",
    "    train_df = cv_df[trains]\n",
    "    test_mean = test_df.mean(axis=1)\n",
    "    train_mean = train_df.mean(axis=1)\n",
    "    test_stdv = test_df.std(axis=1, ddof=0)\n",
    "    train_stdv = train_df.std(axis=1, ddof=0)\n",
    "    new_columns = [\"test_mean\", \"test_stdv\", \"train_mean\", \"train_stdv\"]\n",
    "    new_series = [test_mean, test_stdv, train_mean, train_stdv]\n",
    "\n",
    "    for i in range(len(new_columns)):\n",
    "        new_serie = new_series[i]\n",
    "        new_column = new_columns[i]\n",
    "        cv_df[new_column] = new_serie\n",
    "    cv_df = cv_df[new_columns+tests+trains]\n",
    "    return cv_df\n",
    "def get_all_folds_ids(df, k):\n",
    "    np.random.seed(42)\n",
    "    # using aggregated indices for splitting\n",
    "    X = copy(df[[\"id\", \"code\"]].drop_duplicates().values[:,0])\n",
    "    y = copy(df[[\"id\", \"code\"]].drop_duplicates().values[:,1])\n",
    "    fold_ids = [] # storing fold ids 0 / 0_0 / 0_1 ...\n",
    "    all_folds = [] # storing all folds [(train, test), ...]\n",
    "    # folds for train_test and successive sub_folds\n",
    "    skf = SKF(n_splits=k, shuffle=True, random_state=42)\n",
    "    folds = copy([[train_ids, test_ids] for train_ids, test_ids in skf.split(X, y)])\n",
    "    for i in range(k):\n",
    "        fold = folds[i]\n",
    "        train_ids = fold[0]\n",
    "        sub_X = copy(X[train_ids])\n",
    "        sub_y = copy(y[train_ids])\n",
    "        skf = SKF(n_splits=k, shuffle=True, random_state=42)\n",
    "        sub_folds = copy([[sub_X[train_is].astype(int), sub_X[test_is].astype(int)] for train_is, test_is in skf.split(sub_X, sub_y)])\n",
    "        all_folds += [fold] + sub_folds\n",
    "        fold_ids += [str(i)] + [str(i)+\"_\"+str(j) for j in range(k)]\n",
    "    return all_folds, fold_ids\n",
    "def get_date_week_month_df(df):\n",
    "    week_month_data = []\n",
    "    weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    ids = copy(df[\"id\"].unique())\n",
    "    for idd in ids:\n",
    "        id_date = copy(df[df[\"id\"]==idd][\"date\"])\n",
    "        n = copy(len(id_date))\n",
    "\n",
    "        # week\n",
    "        id_weeks = copy(id_date.dt.weekday_name.value_counts())\n",
    "        week_array = copy(np.zeros(7))\n",
    "        for i in range(len(weekdays)):\n",
    "            weekday = copy(weekdays[i])\n",
    "            try:\n",
    "                weekday_count = copy(id_weeks[weekday])\n",
    "                week_array[i] = copy(weekday_count)\n",
    "            except:\n",
    "                pass\n",
    "        week_array = copy(week_array / n)\n",
    "\n",
    "        # month\n",
    "        id_months = copy(id_date.dt.month_name().value_counts())\n",
    "        month_array = copy(np.zeros(12))\n",
    "        for i in range(len(months)):\n",
    "            month = copy(months[i])\n",
    "            try:\n",
    "                month_count = copy(id_months[month])\n",
    "                month_array[i] = copy(month_count)\n",
    "            except:\n",
    "                pass\n",
    "        month_array = copy(month_array / n)\n",
    "\n",
    "        week_month_array = copy(np.concatenate((week_array, month_array)))\n",
    "        week_month_data += copy([week_month_array])\n",
    "\n",
    "    columns = copy([weekday.lower() for weekday in weekdays] + [month.lower() for month in months])\n",
    "    week_month_df = pd.DataFrame(\n",
    "        data=week_month_data,\n",
    "        index=ids,\n",
    "        columns=columns,\n",
    "    )\n",
    "    return copy(week_month_df)\n",
    "def get_scores_df(data_folder):\n",
    "    agg_df = joblib.load(data_folder + \"agg_df.pkl\")\n",
    "    labels = sorted(agg_df[\"code\"].unique(), key=lambda x: int(x))\n",
    "    labels.remove(\"4\")\n",
    "    scores_df = copy(agg_df[[\"code\"]])\n",
    "    for label in labels:\n",
    "        # getting LR test scores\n",
    "        clf_score_column = label +\"_lr\"\n",
    "        scores_df[clf_score_column] = None\n",
    "        df = joblib.load(data_folder + \"label_\"+label+\"_hpocv_df.pkl\")\n",
    "        for k in range(10):\n",
    "            mean = df[[str(k)+\"_\"+str(l)+\"_test\" for l in range(10)]].mean(axis=1)\n",
    "            stdv = df[[str(k)+\"_\"+str(l)+\"_test\" for l in range(10)]].std(axis=1, ddof=0)\n",
    "            stat_df = df[[]].copy()\n",
    "            stat_df[\"mean\"] = mean\n",
    "            stat_df[\"stdv\"] = stdv\n",
    "            best_loc = stat_df.sort_values(by=[\"mean\", \"stdv\"], ascending=[False, True]).iloc[0].name\n",
    "            c, l1_ratio = df.loc[best_loc, [\"c\", \"l1_ratio\"]]\n",
    "            test_agg_df = joblib.load(data_folder + str(k)+\"_test_agg_df.pkl\")\n",
    "            clfs_fold_label = joblib.load(data_folder + \"clfs_\"+str(k)+\"_label_\"+label+\".pkl\")\n",
    "            clf = clfs_fold_label[c, l1_ratio]\n",
    "            X_test = test_agg_df[test_agg_df.columns[:-1]]\n",
    "            y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "            scores_df.loc[test_X.index, clf_score_column] = y_pred\n",
    "\n",
    "        # getting XGB test scores\n",
    "        clf_score_column = label +\"_xgb\"\n",
    "        scores_df[clf_score_column] = None\n",
    "        for k in range(10):\n",
    "            test_agg_df = joblib.load(data_folder + str(k)+\"_test_agg_df.pkl\")\n",
    "            train_agg_df = joblib.load(data_folder + str(k)+\"_train_agg_df.pkl\")\n",
    "            test_X = test_agg_df[test_agg_df.columns[:-1]]\n",
    "            train_X = train_agg_df[train_agg_df.columns[:-1]]\n",
    "            train_y = (train_agg_df[train_agg_df.columns[-1]]==label).values.astype(int)\n",
    "            #### calibrating using only CV holdout + balanced\n",
    "            calibrators = []\n",
    "            for l in range(10):\n",
    "                calibrator = LR(penalty=\"none\", class_weight=\"balanced\", random_state=42)\n",
    "                sub_clf = XGBC(random_state=42, n_jobs=-1, objective=\"binary:logitraw\")\n",
    "                sub_test_agg_df = joblib.load(data_folder + str(k)+\"_\"+str(l)+\"_test_agg_df.pkl\")\n",
    "                sub_train_agg_df = joblib.load(data_folder + str(k)+\"_\"+str(l)+\"_train_agg_df.pkl\")\n",
    "                sub_X_test = sub_test_agg_df[sub_test_agg_df.columns[:-1]]\n",
    "                sub_y_test = (sub_test_agg_df[sub_test_agg_df.columns[-1]]==label).values.astype(int)\n",
    "                sub_X_train = sub_train_agg_df[sub_train_agg_df.columns[:-1]]\n",
    "                sub_y_train = (sub_train_agg_df[sub_train_agg_df.columns[-1]]==label).values.astype(int)\n",
    "                sub_clf.fit(sub_X_train, sub_y_train)\n",
    "                sub_test_scores = sub_clf.predict_proba(sub_X_test)[:,1].reshape(-1,1)\n",
    "                calibrator.fit(sub_test_scores, sub_y_test)\n",
    "                calibrators += [copy(calibrator)]\n",
    "            ###\n",
    "            clf = XGBC(random_state=42, n_jobs=-1, objective=\"binary:logitraw\")\n",
    "            clf.fit(train_X, train_y)\n",
    "            ###\n",
    "            pre_scores = clf.predict_proba(test_X)[:,1].reshape(-1,1)\n",
    "            y_preds = []\n",
    "            for calibrator in calibrators:\n",
    "                y_preds += [calibrator.predict_proba(pre_scores)[:,1].tolist()]\n",
    "            y_preds = np.array(y_preds)\n",
    "            y_pred = np.mean(y_preds, axis=0).tolist()\n",
    "            scores_df.loc[test_X.index, clf_score_column] = y_pred\n",
    "    return scores_df\n",
    "def get_ton_bin_df(id_tons, ton_bins):\n",
    "    ton_data = []\n",
    "    ids = copy(list(id_tons.keys()))\n",
    "    for idd in ids:\n",
    "        ton_features_array = copy(np.zeros(shape=(11)))\n",
    "        idd_tons = copy(id_tons[idd])\n",
    "        n = copy(len(idd_tons))\n",
    "        for idd_ton in idd_tons:\n",
    "            ton_features_array[1:] += copy(ton_bins.isin([idd_ton]).astype(int))\n",
    "        idd_ton_array = copy(ton_features_array / n)\n",
    "        idd_ton_array[0] = copy(n)\n",
    "        ton_data += copy([idd_ton_array])\n",
    "    ton_bin_data = copy(np.array(ton_data))\n",
    "    ton_bin_df = pd.DataFrame(\n",
    "        data=ton_bin_data,\n",
    "        index=ids,\n",
    "        columns=[\"n\"] + [\"ton_\"+str(i) for i in range(10)]\n",
    "    )\n",
    "    return copy(ton_bin_df)\n",
    "def get_lr_hyperparams_df(data_folder):\n",
    "    labels = sorted(\n",
    "        [item.split(\"label_\")[1].split(\"_\")[0] for item in os.listdir(data_folder) if (\n",
    "            (\"label_\" in item) and (\"hpocv_df.pkl\" in item)\n",
    "        )],\n",
    "        key=lambda x: int(x))\n",
    "    lr_hyperparams_data = []\n",
    "    for label in labels:\n",
    "        df = joblib.load(data_folder + \"label_\"+label+\"_hpocv_df.pkl\")\n",
    "        test_columns = [str(i) + \"_test\" for i in range(10)]\n",
    "        mean = df[test_columns].mean(axis=1)\n",
    "        stdv = df[test_columns].std(axis=1, ddof=0)\n",
    "        df[\"mean\"] = mean\n",
    "        df[\"stdv\"] = stdv\n",
    "        c, l1_ratio = df.sort_values(by=[\"mean\", \"stdv\"], ascending=[False, True]).iloc[0][[\"c\", \"l1_ratio\"]].values\n",
    "        lr_hyperparams_data += [[c, l1_ratio]]\n",
    "        \n",
    "    lr_hyperparams_df = pd.DataFrame(\n",
    "        data=lr_hyperparams_data,\n",
    "        index=labels,\n",
    "        columns=[\"c\",\"l1_ratio\"]\n",
    "    )\n",
    "    return lr_hyperparams_df    \n",
    "def get_lr_performance_df(data_folder):\n",
    "    labels = sorted(\n",
    "        [item.split(\"label_\")[1].split(\"_\")[0] for item in os.listdir(data_folder) if (\n",
    "            (\"label_\" in item) and (\"hpocv_df.pkl\" in item)\n",
    "        )],\n",
    "        key=lambda x: int(x))\n",
    "    lr_performance_data = []\n",
    "    for label in labels:\n",
    "        df = joblib.load(data_folder + \"label_\"+label+\"_hpocv_df.pkl\")\n",
    "        label_performances = []\n",
    "        for i in range(10): # outer_folds\n",
    "            infold_test_columns = [str(i) + \"_\" + str(j) + \"_test\" for j in range(10)] # inner_folds\n",
    "            infold_test_df = copy(df[infold_test_columns])\n",
    "            mean = infold_test_df.mean(axis=1)\n",
    "            stdv = infold_test_df.std(axis=1, ddof=0)\n",
    "            infold_test_df[\"mean\"] = mean\n",
    "            infold_test_df[\"stdv\"] = stdv\n",
    "            infold_test_df.sort_values(by=[\"mean\", \"stdv\"], ascending=[False, True]).iloc[0]\n",
    "            best_loc = infold_test_df.sort_values(by=[\"mean\", \"stdv\"], ascending=[False, True]).index[0]\n",
    "            test_train_columns = [str(i)+\"_test\", str(i)+\"_train\"]\n",
    "            test_train_values = df.loc[best_loc, test_train_columns].values.tolist()\n",
    "            label_performances += [test_train_values]\n",
    "        label_performances = np.array(label_performances)\n",
    "        lr_performance_data += [[\n",
    "            label_performances.mean(axis=0)[0],\n",
    "            label_performances.std(axis=0, ddof=0)[0],\n",
    "            label_performances.mean(axis=0)[1],\n",
    "            label_performances.std(axis=0, ddof=0)[1]\n",
    "        ] + label_performances[:, 0].tolist() + label_performances[:, 1].tolist()]\n",
    "    lr_performance_columns = [\"test_mean\", \"test_stdv\", \"train_mean\", \"train_stdv\"] + [str(i)+\"_test\" for i in range(10)] + [str(i)+\"_train\" for i in range(10)]\n",
    "    lr_performance_df = pd.DataFrame(\n",
    "        data=lr_performance_data,\n",
    "        index=labels,\n",
    "        columns=lr_performance_columns\n",
    "    )\n",
    "    return lr_performance_df\n",
    "def get_date_bin_df(id_dates, date_bins):\n",
    "    date_data = []\n",
    "    ids = copy(list(id_dates.keys()))\n",
    "    for idd in ids:\n",
    "        idd_date_array = copy(np.zeros(shape=(10)))\n",
    "        idd_dates = copy(id_dates[idd])\n",
    "        n = copy(len(idd_dates))\n",
    "        if n>0:\n",
    "            for idd_date in idd_dates:\n",
    "                idd_date_array += copy(date_bins.isin([idd_date]).astype(int))\n",
    "            idd_date_array = copy(idd_date_array / n)\n",
    "        date_data += copy([idd_date_array])\n",
    "\n",
    "    date_bin_data = copy(np.array(date_data))\n",
    "    date_bin_df = copy(pd.DataFrame(\n",
    "        data=date_bin_data,\n",
    "        index=ids,\n",
    "        columns=[\"date_\"+str(i) for i in range(10)]\n",
    "    ))\n",
    "    return copy(date_bin_df)\n",
    "def get_label_hpocv_df(fold_ids, label_hpocv_dfs):\n",
    "    for i in range(len(fold_ids)):\n",
    "        fold_id = fold_ids[i]\n",
    "        if i==0:\n",
    "            label_hpocv_df = copy(label_hpocv_dfs[i])\n",
    "            label_hpocv_df.columns = [\"c\", \"l1_ratio\", fold_id + \"_test\", fold_id + \"_train\"]\n",
    "            label_hpocv_df = copy(label_hpocv_df)\n",
    "        else:\n",
    "            fold_label_hpocv_df = copy(label_hpocv_dfs[i])\n",
    "            fold_label_hpocv_df = copy(fold_label_hpocv_df[[\"test\", \"train\"]])\n",
    "            fold_label_hpocv_df.columns = [fold_id + \"_test\", fold_id + \"_train\"]\n",
    "            label_hpocv_df = pd.concat(\n",
    "                (\n",
    "                    label_hpocv_df, fold_label_hpocv_df\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "    return label_hpocv_df\n",
    "def get_agg_df(df, id_tons, ton_bins, id_dates, date_bins):\n",
    "    agg_df = copy(df[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"use\",\n",
    "            \"type_export\", \"type_import\", \"type_transit\", \n",
    "            \"mode_inland_waters\", \"mode_road\", \"mode_sea\", \"mode_train\",\n",
    "            \"total\",\n",
    "            \"code\"\n",
    "        ]\n",
    "    ].drop_duplicates())\n",
    "    agg_df.index = copy(agg_df[\"id\"].values)\n",
    "    agg_df = copy(agg_df.drop(columns=\"id\"))\n",
    "    agg_df_left = copy(agg_df[agg_df.columns[:-1]])\n",
    "    agg_df_right = copy(agg_df[[agg_df.columns[-1]]])\n",
    "\n",
    "    ton_bin_df = copy(get_ton_bin_df(copy(id_tons), copy(ton_bins)))\n",
    "    date_bin_df = copy(get_date_bin_df(copy(id_dates), copy(date_bins)))\n",
    "    week_month_df = copy(get_date_week_month_df(copy(df)))\n",
    "\n",
    "    agg_df = copy(pd.concat(\n",
    "        (\n",
    "            agg_df_left,\n",
    "            ton_bin_df,\n",
    "            date_bin_df,\n",
    "            week_month_df,\n",
    "            agg_df_right\n",
    "        ),\n",
    "        axis=1\n",
    "    ))\n",
    "    return copy(agg_df)\n",
    "def make_agg_train_test_dfs(i, all_folds, fold_ids, df, data_folder):\n",
    "    # Training set\n",
    "    fold = copy(all_folds[i])\n",
    "    fold_id = copy(fold_ids[i])\n",
    "    train_ids = copy(fold[0])\n",
    "    fold_train_df = copy(copy(df).loc[copy(df[\"id\"]).isin(train_ids)])\n",
    "    \n",
    "    # creating train id_tons and ton_bins\n",
    "    fold_train_id_tons = copy(get_id_tons(copy(fold_train_df)))\n",
    "    fold_train_ton_bins = copy(get_ton_bins(copy(fold_train_df)))\n",
    "    \n",
    "    # creating train id_dates and date_bins\n",
    "    fold_train_id_dates = copy(get_id_dates(copy(fold_train_df)))\n",
    "    fold_train_date_bins = copy(get_date_bins(copy(fold_train_df)))\n",
    "    \n",
    "    # creating aggregated fold_train_set\n",
    "    fold_train_agg_df = copy(get_agg_df(\n",
    "        copy(fold_train_df), copy(fold_train_id_tons), copy(fold_train_ton_bins), copy(fold_train_id_dates), copy(fold_train_date_bins)\n",
    "    ))\n",
    "    \n",
    "    # Testing set\n",
    "    test_ids = fold[1]\n",
    "    fold_test_df = copy(copy(df).loc[copy(df[\"id\"]).isin(test_ids)])\n",
    "    \n",
    "    # creating test id_tons\n",
    "    fold_test_id_tons = copy(get_id_tons(copy(fold_test_df)))\n",
    "    \n",
    "    # creating test id_dates\n",
    "    fold_test_id_dates = copy(get_id_dates(copy(fold_test_df)))\n",
    "    \n",
    "    # creating aggregated fold_test_set using train_bins\n",
    "    fold_test_agg_df = copy(get_agg_df(\n",
    "        copy(fold_test_df), copy(fold_test_id_tons), copy(fold_train_ton_bins), copy(fold_test_id_dates), copy(fold_train_date_bins)\n",
    "    ))\n",
    "    \n",
    "    # Robust-scaling \"total\" and \"n\" values\n",
    "    # Minimizes the effect of outlying values in data\n",
    "    fold_train_med_n = copy(np.median(fold_train_agg_df[\"n\"]))\n",
    "    fold_train_iqr_n = copy(scipy.stats.iqr(fold_train_agg_df[\"n\"]))\n",
    "    fold_train_med_total = copy(np.median(fold_train_agg_df[\"total\"]))\n",
    "    fold_train_iqr_total = copy(scipy.stats.iqr(fold_train_agg_df[\"total\"]))\n",
    "    fold_test_agg_df[\"n\"] = copy((fold_test_agg_df[\"n\"] - fold_train_med_n) / fold_train_iqr_n)\n",
    "    fold_train_agg_df[\"n\"] = copy((fold_train_agg_df[\"n\"] - fold_train_med_n) / fold_train_iqr_n)\n",
    "    fold_test_agg_df[\"total\"] = copy((fold_test_agg_df[\"total\"] - fold_train_med_total) / fold_train_iqr_total)\n",
    "    fold_train_agg_df[\"total\"] = copy((fold_train_agg_df[\"total\"] - fold_train_med_total) / fold_train_iqr_total)\n",
    "    \n",
    "    # saving files\n",
    "    joblib.dump(copy(fold_train_agg_df), data_folder + fold_id +\"_train_agg_df.pkl\");\n",
    "    joblib.dump(copy(fold_test_agg_df), data_folder + fold_id+\"_test_agg_df.pkl\");\n",
    "    fold_train_agg_df.to_csv(data_folder + fold_id+\"_train_agg_df.csv\")\n",
    "    fold_test_agg_df.to_csv(data_folder + fold_id+\"_test_agg_df.csv\")\n",
    "def get_label_cv_dfs(i, labels, fold_ids, data_folder, clf_template):\n",
    "    label = copy(labels[i])\n",
    "    label_cv_data = []\n",
    "    label_cv_columns = []\n",
    "    for j in range(len(fold_ids)):\n",
    "        fold_id = copy(fold_ids[j])\n",
    "        test_df = copy(joblib.load(data_folder + fold_id + \"_test_agg_df.pkl\"))\n",
    "        train_df = copy(joblib.load(data_folder + fold_id + \"_train_agg_df.pkl\"))\n",
    "        X = test_df.columns[:-1]\n",
    "        y = test_df.columns[-1]\n",
    "        X_train, X_test = train_df[X], test_df[X]\n",
    "        y_train, y_test = train_df[y]==label, test_df[y]==label\n",
    "        \n",
    "        #clf = XGBC(n_estimators=100, max_depth=3, random_state=42, n_jobs=-1)\n",
    "        clf = copy(clf_template)\n",
    "        #clf = RFC(random_state=42, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_test_pred = clf.predict_proba(X_test)[:,1]\n",
    "        y_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "    \n",
    "        test_score = roc_auc_score(y_test, y_test_pred)\n",
    "        train_score = roc_auc_score(y_train, y_train_pred)\n",
    "        #test_score = average_precision_score(y_test, y_test_pred)\n",
    "        #train_score = average_precision_score(y_train, y_train_pred)\n",
    "        \n",
    "        label_cv_data += [test_score, train_score]\n",
    "        label_cv_columns += [fold_id +\"_test\", fold_id +\"_train\"]\n",
    "\n",
    "    label_cv_df = pd.DataFrame(\n",
    "        data=[label_cv_data],\n",
    "        index=[label],\n",
    "        columns = label_cv_columns\n",
    "    )\n",
    "    return label_cv_df\n",
    "def get_label_hpocv_dfs(i, label, hyperparam_sets, fold_ids, data_folder):\n",
    "    fold_id = copy(fold_ids)[i]\n",
    "    fold_train_agg_df = copy(joblib.load(data_folder + fold_id + \"_train_agg_df.pkl\"))\n",
    "    fold_test_agg_df = copy(joblib.load(data_folder + fold_id +\"_test_agg_df.pkl\"))\n",
    "\n",
    "    X_train = copy(fold_train_agg_df[fold_train_agg_df.columns[:-1]])\n",
    "    y_train = copy(fold_train_agg_df[fold_train_agg_df.columns[-1]])\n",
    "    y_train_bin = copy((y_train==label).values.astype(int))\n",
    "    \n",
    "    X_test = copy(fold_test_agg_df[fold_test_agg_df.columns[:-1]])\n",
    "    y_test = copy(fold_test_agg_df[fold_test_agg_df.columns[-1]])\n",
    "    y_true = copy((y_test==label).values.astype(int))\n",
    "    \n",
    "    clfs = {}\n",
    "    hyperparam_scores = []\n",
    "    for hyperparams in hyperparam_sets:\n",
    "        c, l1_ratio = copy(hyperparams)\n",
    "        clf = LR(\n",
    "            C=c,\n",
    "            n_jobs=1,\n",
    "            max_iter=1e5,\n",
    "            solver=\"saga\",\n",
    "            random_state=42,\n",
    "            l1_ratio=l1_ratio,\n",
    "            penalty=\"elasticnet\",\n",
    "            class_weight=\"balanced\", \n",
    "        ).fit(\n",
    "            X=X_train,\n",
    "            y=y_train_bin\n",
    "        )\n",
    "        clfs[hyperparams] = copy(clf)\n",
    "        test_roc_auc = copy(roc_auc_score(y_true, clf.predict_proba(X_test)[:,1]))\n",
    "        train_roc_auc = copy(roc_auc_score(y_train_bin, clf.predict_proba(X_train)[:,1]))\n",
    "        hyperparam_scores += [[c, l1_ratio, test_roc_auc, train_roc_auc]]\n",
    "    #saving classifiers    \n",
    "    joblib.dump(clfs, data_folder + \"clfs_\" + fold_id + \"_label_\" + label + \".pkl\")\n",
    "    label_fold_hpocv_df = pd.DataFrame(\n",
    "        data=hyperparam_scores,\n",
    "        index=range(len(hyperparam_sets)),\n",
    "        columns = [\"c\", \"l1_ratio\", \"test\", \"train\"]\n",
    "    )\n",
    "    return label_fold_hpocv_df\n",
    "def get_tt_compare_df(data_folder, clf1_performance_df_str=\"lr_performance_df\", clf2_performance_df_str=\"xgb_performance_df\"):\n",
    "    from scipy.stats import t\n",
    "    from math import sqrt\n",
    "    from statistics import stdev\n",
    "\n",
    "    def corrected_dependent_ttest(data1, data2, k):\n",
    "        \"\"\" https://gist.github.com/jensdebruijn/13e8eeda85eb8644ac2a4ac4c3b8e732 \"\"\"\n",
    "        n = len(data1)\n",
    "        differences = [(data1[i]-data2[i]) for i in range(n)]\n",
    "        sd = stdev(differences)\n",
    "        divisor = 1 / n * sum(differences)\n",
    "        test_training_ratio = 1 / (k-1)\n",
    "        denominator = sqrt(1 / n + test_training_ratio) * sd\n",
    "        t_stat = divisor / denominator\n",
    "        # degrees of freedom\n",
    "        df = n - 1\n",
    "        # calculate the p-value\n",
    "        p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "        # return everything\n",
    "        return t_stat, p\n",
    "    labels = sorted(\n",
    "        [item.split(\"label_\")[1].split(\"_\")[0] for item in os.listdir(data_folder) if (\n",
    "            (\"label_\" in item) and (\"hpocv_df.pkl\" in item)\n",
    "        )],\n",
    "        key=lambda x: int(x))\n",
    "    test_pvals = []\n",
    "    train_pvals = []\n",
    "    clf1_pvals = []\n",
    "    clf2_pvals = []\n",
    "    clf1_performance_df = joblib.load(data_folder + clf1_performance_df_str+\".pkl\")\n",
    "    clf2_performance_df = joblib.load(data_folder + clf2_performance_df_str+\".pkl\")\n",
    "    for label in labels:\n",
    "        test_pval = corrected_dependent_ttest(\n",
    "            clf1_performance_df.loc[label, [str(i)+\"_test\" for i in range(10)]].values,\n",
    "            clf2_performance_df.loc[label, [str(i)+\"_test\" for i in range(10)]].values,\n",
    "            10\n",
    "        )[-1]\n",
    "        train_pval = corrected_dependent_ttest(\n",
    "            clf1_performance_df.loc[label, [str(i)+\"_train\" for i in range(10)]].values,\n",
    "            clf2_performance_df.loc[label, [str(i)+\"_train\" for i in range(10)]].values,\n",
    "            10\n",
    "        )[-1]\n",
    "\n",
    "        clf1_pval = scipy.stats.ttest_ind(\n",
    "            clf1_performance_df.loc[label, [str(i)+\"_test\" for i in range(10)]].values,\n",
    "            clf1_performance_df.loc[label, [str(i)+\"_train\" for i in range(10)]].values,\n",
    "            equal_var = False\n",
    "        )[1]\n",
    "\n",
    "        clf2_pval = scipy.stats.ttest_ind(\n",
    "            clf2_performance_df.loc[label, [str(i)+\"_test\" for i in range(10)]].values,\n",
    "            clf2_performance_df.loc[label, [str(i)+\"_train\" for i in range(10)]].values,\n",
    "            equal_var = False\n",
    "        )[1]\n",
    "\n",
    "        clf1_pvals += [clf1_pval]\n",
    "        clf2_pvals += [clf2_pval]\n",
    "        test_pvals += [test_pval]\n",
    "        train_pvals += [train_pval]\n",
    "\n",
    "    clf1_performance_df[\"tt_pval\"] = clf1_pvals\n",
    "    clf2_performance_df[\"tt_pval\"] = clf2_pvals\n",
    "    columns = [\"test_mean\", \"test_stdv\", \"tt_pval\", \"train_mean\", \"train_stdv\"]\n",
    "    keys = (clf1_performance_df_str.split(\"_\")[0], clf2_performance_df_str.split(\"_\")[0])\n",
    "    tt_compare_df = pd.concat([clf1_performance_df[columns], clf2_performance_df[columns]], axis=1, keys=keys)\n",
    "    tt_compare_df[\"test_tt_pval\"] = test_pvals\n",
    "    tt_compare_df[\"train_tt_pval\"] = train_pvals\n",
    "    columns = copy(tt_compare_df.columns)\n",
    "    left_columns = copy(columns[:5])\n",
    "    tt_columns = copy(columns[-2:])\n",
    "    right_columns = copy(columns[5:10])\n",
    "    ordered_columns = left_columns.append(tt_columns)\n",
    "    ordered_columns = ordered_columns.append(right_columns)\n",
    "    tt_compare_df = tt_compare_df[ordered_columns]\n",
    "    return tt_compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and storing aggregated train/test datasets\n",
    "    0_train_agg_df, 0_test_agg_df -> train and test sets of fold 0\n",
    "        \n",
    "        0_0_train_agg_df -> train_0 of subfold in 0_train_agg_df (for HPO)\n",
    "    \n",
    "        0_1_train_agg_df -> train_1 of subfold in 0_train_agg_df (for HPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/data/pereirabarataap/EVOA_revisited/\"\n",
    "df = joblib.load(data_folder + \"waste_df.pkl\")\n",
    "k = 10 # k-folds\n",
    "\n",
    "all_folds, fold_ids = get_all_folds_ids(df, k)\n",
    "Parallel(n_jobs=-1, backend=\"loky\", temp_folder=data_folder)(\n",
    "    delayed(make_agg_train_test_dfs)(copy(i), copy(all_folds), copy(fold_ids), copy(df), copy(data_folder)) for i in range(len(all_folds))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and storing aggregated full-dataset\n",
    "    \n",
    "    for last-stage fitting -> projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = get_agg_df(df, get_id_tons(df), get_ton_bins(df), get_id_dates(df), get_date_bins(df))\n",
    "\n",
    "# robust-scaling of \"total\" and \"n\" features\n",
    "agg_df_med_n = np.median(agg_df[\"n\"])\n",
    "agg_df_iqr_n = scipy.stats.iqr(agg_df[\"n\"])\n",
    "agg_df_med_total = np.median(agg_df[\"total\"])\n",
    "agg_df_iqr_total = scipy.stats.iqr(agg_df[\"total\"])\n",
    "agg_df[\"n\"] = (agg_df[\"n\"] - agg_df_med_n) / agg_df_iqr_n\n",
    "agg_df[\"total\"] = (agg_df[\"total\"] - agg_df_med_total) / agg_df_iqr_total\n",
    "\n",
    "# saving files\n",
    "joblib.dump(agg_df, data_folder + \"agg_df.pkl\")\n",
    "agg_df.to_csv(data_folder + \"agg_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "\n",
    "##### Waste code *4* has only 8 instances total.\n",
    "##### We will not be able to CV this category for performance.\n",
    "##### However, we will keep those instances to train other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression\n",
    "        Elasticnet regularisation\n",
    "            HyperParameterOptimisation\n",
    "                C (lambda), L1 Ratio\n",
    "                    Circa 100 hours runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(df[\"code\"].unique(), key=lambda x: int(x))\n",
    "labels.remove(\"4\") # unable to cv model on 8 istances.\n",
    "cs = np.geomspace(1e-3, 1e3, 21)\n",
    "l1_ratios = np.linspace(0, 1, 21)\n",
    "hyperparam_sets = []\n",
    "for c in cs:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        hyperparm_set = (c, l1_ratio)\n",
    "        hyperparam_sets += [hyperparm_set]\n",
    "\n",
    "for label in labels:\n",
    "    label_hpocv_dfs = Parallel(n_jobs=-1, backend=\"loky\", temp_folder=data_folder)(\n",
    "        delayed(get_label_hpocv_dfs)(copy(i), copy(label), copy(hyperparam_sets), copy(fold_ids), copy(data_folder)) for i in range(len(fold_ids))\n",
    "    )\n",
    "    # merging results into one dataframe\n",
    "    label_hpocv_df = get_label_hpocv_df(fold_ids, label_hpocv_dfs)\n",
    "    # saving results\n",
    "    joblib.dump(label_hpocv_df, data_folder + \"label_\"+str(label)+\"_hpocv_df.pkl\")\n",
    "    label_hpocv_df.to_csv(data_folder + \"label_\"+str(label)+\"_hpocv_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_stdv</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_stdv</th>\n",
       "      <th>0_test</th>\n",
       "      <th>1_test</th>\n",
       "      <th>2_test</th>\n",
       "      <th>3_test</th>\n",
       "      <th>4_test</th>\n",
       "      <th>5_test</th>\n",
       "      <th>...</th>\n",
       "      <th>0_train</th>\n",
       "      <th>1_train</th>\n",
       "      <th>2_train</th>\n",
       "      <th>3_train</th>\n",
       "      <th>4_train</th>\n",
       "      <th>5_train</th>\n",
       "      <th>6_train</th>\n",
       "      <th>7_train</th>\n",
       "      <th>8_train</th>\n",
       "      <th>9_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.982791</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.988298</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.972926</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.975983</td>\n",
       "      <td>0.995197</td>\n",
       "      <td>0.979476</td>\n",
       "      <td>0.994760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984701</td>\n",
       "      <td>0.983238</td>\n",
       "      <td>0.986679</td>\n",
       "      <td>0.986009</td>\n",
       "      <td>0.993963</td>\n",
       "      <td>0.986606</td>\n",
       "      <td>0.986543</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.992961</td>\n",
       "      <td>0.987527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.868437</td>\n",
       "      <td>0.043846</td>\n",
       "      <td>0.907673</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.813069</td>\n",
       "      <td>0.902570</td>\n",
       "      <td>0.803080</td>\n",
       "      <td>0.888007</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914940</td>\n",
       "      <td>0.907804</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.901736</td>\n",
       "      <td>0.906522</td>\n",
       "      <td>0.910071</td>\n",
       "      <td>0.899985</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.903249</td>\n",
       "      <td>0.910466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.868277</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.884360</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.877679</td>\n",
       "      <td>0.894610</td>\n",
       "      <td>0.883201</td>\n",
       "      <td>0.827348</td>\n",
       "      <td>0.863922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885420</td>\n",
       "      <td>0.884550</td>\n",
       "      <td>0.881482</td>\n",
       "      <td>0.883226</td>\n",
       "      <td>0.890789</td>\n",
       "      <td>0.884636</td>\n",
       "      <td>0.887393</td>\n",
       "      <td>0.883952</td>\n",
       "      <td>0.881209</td>\n",
       "      <td>0.880941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672360</td>\n",
       "      <td>0.091644</td>\n",
       "      <td>0.820775</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.664069</td>\n",
       "      <td>0.611446</td>\n",
       "      <td>0.695237</td>\n",
       "      <td>0.789838</td>\n",
       "      <td>0.760777</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811174</td>\n",
       "      <td>0.806995</td>\n",
       "      <td>0.817007</td>\n",
       "      <td>0.830051</td>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.829287</td>\n",
       "      <td>0.807329</td>\n",
       "      <td>0.839483</td>\n",
       "      <td>0.812959</td>\n",
       "      <td>0.839260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.740365</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.754964</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.780550</td>\n",
       "      <td>0.756385</td>\n",
       "      <td>0.693033</td>\n",
       "      <td>0.679107</td>\n",
       "      <td>0.744741</td>\n",
       "      <td>0.685399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>0.755316</td>\n",
       "      <td>0.754382</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>0.747725</td>\n",
       "      <td>0.755941</td>\n",
       "      <td>0.749551</td>\n",
       "      <td>0.754563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775782</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.784155</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.793171</td>\n",
       "      <td>0.741358</td>\n",
       "      <td>0.787850</td>\n",
       "      <td>0.796036</td>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.777050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782008</td>\n",
       "      <td>0.786648</td>\n",
       "      <td>0.783303</td>\n",
       "      <td>0.782225</td>\n",
       "      <td>0.783881</td>\n",
       "      <td>0.784236</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.785719</td>\n",
       "      <td>0.784729</td>\n",
       "      <td>0.784745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.820357</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.784184</td>\n",
       "      <td>0.787138</td>\n",
       "      <td>0.823669</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.773826</td>\n",
       "      <td>0.791685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>0.824009</td>\n",
       "      <td>0.818445</td>\n",
       "      <td>0.826046</td>\n",
       "      <td>0.820473</td>\n",
       "      <td>0.820821</td>\n",
       "      <td>0.809809</td>\n",
       "      <td>0.821939</td>\n",
       "      <td>0.819022</td>\n",
       "      <td>0.818899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.046674</td>\n",
       "      <td>0.897139</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.823571</td>\n",
       "      <td>0.898457</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.838362</td>\n",
       "      <td>0.768990</td>\n",
       "      <td>0.920580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914214</td>\n",
       "      <td>0.892446</td>\n",
       "      <td>0.893068</td>\n",
       "      <td>0.886449</td>\n",
       "      <td>0.919682</td>\n",
       "      <td>0.898366</td>\n",
       "      <td>0.894682</td>\n",
       "      <td>0.887452</td>\n",
       "      <td>0.899331</td>\n",
       "      <td>0.885704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.736915</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.758426</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.724174</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>0.769401</td>\n",
       "      <td>0.773825</td>\n",
       "      <td>0.656956</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761733</td>\n",
       "      <td>0.763314</td>\n",
       "      <td>0.754794</td>\n",
       "      <td>0.753001</td>\n",
       "      <td>0.770396</td>\n",
       "      <td>0.756933</td>\n",
       "      <td>0.751474</td>\n",
       "      <td>0.756825</td>\n",
       "      <td>0.758096</td>\n",
       "      <td>0.757697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.814735</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.829406</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.797378</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>0.799785</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>0.827523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831419</td>\n",
       "      <td>0.833998</td>\n",
       "      <td>0.829345</td>\n",
       "      <td>0.829255</td>\n",
       "      <td>0.827177</td>\n",
       "      <td>0.827329</td>\n",
       "      <td>0.833801</td>\n",
       "      <td>0.827987</td>\n",
       "      <td>0.826847</td>\n",
       "      <td>0.826903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.860228</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.887660</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.889906</td>\n",
       "      <td>0.847714</td>\n",
       "      <td>0.854972</td>\n",
       "      <td>0.905033</td>\n",
       "      <td>0.846520</td>\n",
       "      <td>0.881036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891390</td>\n",
       "      <td>0.886977</td>\n",
       "      <td>0.888101</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.892626</td>\n",
       "      <td>0.891998</td>\n",
       "      <td>0.884131</td>\n",
       "      <td>0.887386</td>\n",
       "      <td>0.882250</td>\n",
       "      <td>0.891217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>0.668044</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.558170</td>\n",
       "      <td>0.490639</td>\n",
       "      <td>0.711222</td>\n",
       "      <td>0.539417</td>\n",
       "      <td>0.646751</td>\n",
       "      <td>0.655081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678219</td>\n",
       "      <td>0.686694</td>\n",
       "      <td>0.660616</td>\n",
       "      <td>0.678060</td>\n",
       "      <td>0.668152</td>\n",
       "      <td>0.671714</td>\n",
       "      <td>0.681865</td>\n",
       "      <td>0.666018</td>\n",
       "      <td>0.625025</td>\n",
       "      <td>0.664079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.776115</td>\n",
       "      <td>0.034193</td>\n",
       "      <td>0.791715</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.787316</td>\n",
       "      <td>0.755951</td>\n",
       "      <td>0.732848</td>\n",
       "      <td>0.726473</td>\n",
       "      <td>0.777740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787876</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>0.802352</td>\n",
       "      <td>0.790581</td>\n",
       "      <td>0.798650</td>\n",
       "      <td>0.790427</td>\n",
       "      <td>0.780475</td>\n",
       "      <td>0.792941</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.791424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.840980</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.849782</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.839908</td>\n",
       "      <td>0.806227</td>\n",
       "      <td>0.854029</td>\n",
       "      <td>0.853524</td>\n",
       "      <td>0.806834</td>\n",
       "      <td>0.857530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857731</td>\n",
       "      <td>0.852576</td>\n",
       "      <td>0.848093</td>\n",
       "      <td>0.848848</td>\n",
       "      <td>0.852014</td>\n",
       "      <td>0.846958</td>\n",
       "      <td>0.847658</td>\n",
       "      <td>0.850276</td>\n",
       "      <td>0.846243</td>\n",
       "      <td>0.847426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.695149</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.682895</td>\n",
       "      <td>0.687836</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.705018</td>\n",
       "      <td>0.689968</td>\n",
       "      <td>0.679964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695726</td>\n",
       "      <td>0.696147</td>\n",
       "      <td>0.692859</td>\n",
       "      <td>0.695723</td>\n",
       "      <td>0.695450</td>\n",
       "      <td>0.695790</td>\n",
       "      <td>0.694680</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.691823</td>\n",
       "      <td>0.694494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>0.854385</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.869863</td>\n",
       "      <td>0.830601</td>\n",
       "      <td>0.849154</td>\n",
       "      <td>0.876708</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>0.833434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851150</td>\n",
       "      <td>0.856327</td>\n",
       "      <td>0.852828</td>\n",
       "      <td>0.852082</td>\n",
       "      <td>0.855655</td>\n",
       "      <td>0.854014</td>\n",
       "      <td>0.860535</td>\n",
       "      <td>0.854770</td>\n",
       "      <td>0.854505</td>\n",
       "      <td>0.851985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.908823</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.921178</td>\n",
       "      <td>0.890483</td>\n",
       "      <td>0.896283</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>0.870710</td>\n",
       "      <td>0.913852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899792</td>\n",
       "      <td>0.904066</td>\n",
       "      <td>0.903756</td>\n",
       "      <td>0.916717</td>\n",
       "      <td>0.914709</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.914724</td>\n",
       "      <td>0.914515</td>\n",
       "      <td>0.903844</td>\n",
       "      <td>0.907656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.806364</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.808896</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.785697</td>\n",
       "      <td>0.804275</td>\n",
       "      <td>0.819533</td>\n",
       "      <td>0.810237</td>\n",
       "      <td>0.779899</td>\n",
       "      <td>0.803869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.809260</td>\n",
       "      <td>0.807132</td>\n",
       "      <td>0.809079</td>\n",
       "      <td>0.811858</td>\n",
       "      <td>0.808557</td>\n",
       "      <td>0.806417</td>\n",
       "      <td>0.809961</td>\n",
       "      <td>0.808198</td>\n",
       "      <td>0.807636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.719496</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.736445</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.731081</td>\n",
       "      <td>0.737126</td>\n",
       "      <td>0.711568</td>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.708414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738530</td>\n",
       "      <td>0.736334</td>\n",
       "      <td>0.732803</td>\n",
       "      <td>0.737041</td>\n",
       "      <td>0.736829</td>\n",
       "      <td>0.737872</td>\n",
       "      <td>0.741279</td>\n",
       "      <td>0.728201</td>\n",
       "      <td>0.737425</td>\n",
       "      <td>0.738132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_mean  test_stdv  train_mean  train_stdv    0_test    1_test  \\\n",
       "1    0.982791   0.008034    0.988298    0.003852  0.972926  0.986900   \n",
       "2    0.868437   0.043846    0.907673    0.004792  0.813069  0.902570   \n",
       "3    0.868277   0.019864    0.884360    0.002883  0.856481  0.877679   \n",
       "5    0.672360   0.091644    0.820775    0.011965  0.664069  0.611446   \n",
       "6    0.740365   0.038190    0.754964    0.005085  0.780550  0.756385   \n",
       "7    0.775782   0.015962    0.784155    0.001360  0.793171  0.741358   \n",
       "8    0.797800   0.026271    0.820357    0.004259  0.784184  0.787138   \n",
       "9    0.867250   0.046674    0.897139    0.010907  0.823571  0.898457   \n",
       "10   0.736915   0.031900    0.758426    0.005239  0.724174  0.719730   \n",
       "11   0.814735   0.021021    0.829406    0.002619  0.797378  0.771762   \n",
       "12   0.860228   0.031750    0.887660    0.004043  0.889906  0.847714   \n",
       "13   0.608835   0.062540    0.668044    0.016376  0.558170  0.490639   \n",
       "14   0.776115   0.034193    0.791715    0.005597  0.810606  0.787316   \n",
       "15   0.840980   0.018926    0.849782    0.003324  0.839908  0.806227   \n",
       "16   0.694534   0.016414    0.695149    0.001801  0.682895  0.687836   \n",
       "17   0.845450   0.023057    0.854385    0.002597  0.869863  0.830601   \n",
       "18   0.893555   0.014946    0.908823    0.005660  0.921178  0.890483   \n",
       "19   0.806364   0.014495    0.808896    0.001593  0.785697  0.804275   \n",
       "20   0.719496   0.023773    0.736445    0.003396  0.725900  0.731081   \n",
       "\n",
       "      2_test    3_test    4_test    5_test  ...   0_train   1_train   2_train  \\\n",
       "1   0.975983  0.995197  0.979476  0.994760  ...  0.984701  0.983238  0.986679   \n",
       "2   0.803080  0.888007  0.841202  0.875729  ...  0.914940  0.907804  0.914597   \n",
       "3   0.894610  0.883201  0.827348  0.863922  ...  0.885420  0.884550  0.881482   \n",
       "5   0.695237  0.789838  0.760777  0.721554  ...  0.811174  0.806995  0.817007   \n",
       "6   0.693033  0.679107  0.744741  0.685399  ...  0.753623  0.750967  0.762803   \n",
       "7   0.787850  0.796036  0.787546  0.777050  ...  0.782008  0.786648  0.783303   \n",
       "8   0.823669  0.762384  0.773826  0.791685  ...  0.824111  0.824009  0.818445   \n",
       "9   0.892990  0.838362  0.768990  0.920580  ...  0.914214  0.892446  0.893068   \n",
       "10  0.769401  0.773825  0.656956  0.740479  ...  0.761733  0.763314  0.754794   \n",
       "11  0.807432  0.799785  0.826520  0.827523  ...  0.831419  0.833998  0.829345   \n",
       "12  0.854972  0.905033  0.846520  0.881036  ...  0.891390  0.886977  0.888101   \n",
       "13  0.711222  0.539417  0.646751  0.655081  ...  0.678219  0.686694  0.660616   \n",
       "14  0.755951  0.732848  0.726473  0.777740  ...  0.787876  0.789496  0.802352   \n",
       "15  0.854029  0.853524  0.806834  0.857530  ...  0.857731  0.852576  0.848093   \n",
       "16  0.706403  0.705018  0.689968  0.679964  ...  0.695726  0.696147  0.692859   \n",
       "17  0.849154  0.876708  0.841693  0.833434  ...  0.851150  0.856327  0.852828   \n",
       "18  0.896283  0.878307  0.870710  0.913852  ...  0.899792  0.904066  0.903756   \n",
       "19  0.819533  0.810237  0.779899  0.803869  ...  0.810863  0.809260  0.807132   \n",
       "20  0.737126  0.711568  0.691348  0.708414  ...  0.738530  0.736334  0.732803   \n",
       "\n",
       "     3_train   4_train   5_train   6_train   7_train   8_train   9_train  \n",
       "1   0.986009  0.993963  0.986606  0.986543  0.994749  0.992961  0.987527  \n",
       "2   0.901736  0.906522  0.910071  0.899985  0.907359  0.903249  0.910466  \n",
       "3   0.883226  0.890789  0.884636  0.887393  0.883952  0.881209  0.880941  \n",
       "5   0.830051  0.814203  0.829287  0.807329  0.839483  0.812959  0.839260  \n",
       "6   0.755316  0.754382  0.764766  0.747725  0.755941  0.749551  0.754563  \n",
       "7   0.782225  0.783881  0.784236  0.784059  0.785719  0.784729  0.784745  \n",
       "8   0.826046  0.820473  0.820821  0.809809  0.821939  0.819022  0.818899  \n",
       "9   0.886449  0.919682  0.898366  0.894682  0.887452  0.899331  0.885704  \n",
       "10  0.753001  0.770396  0.756933  0.751474  0.756825  0.758096  0.757697  \n",
       "11  0.829255  0.827177  0.827329  0.833801  0.827987  0.826847  0.826903  \n",
       "12  0.880519  0.892626  0.891998  0.884131  0.887386  0.882250  0.891217  \n",
       "13  0.678060  0.668152  0.671714  0.681865  0.666018  0.625025  0.664079  \n",
       "14  0.790581  0.798650  0.790427  0.780475  0.792941  0.792929  0.791424  \n",
       "15  0.848848  0.852014  0.846958  0.847658  0.850276  0.846243  0.847426  \n",
       "16  0.695723  0.695450  0.695790  0.694680  0.698800  0.691823  0.694494  \n",
       "17  0.852082  0.855655  0.854014  0.860535  0.854770  0.854505  0.851985  \n",
       "18  0.916717  0.914709  0.908451  0.914724  0.914515  0.903844  0.907656  \n",
       "19  0.809079  0.811858  0.808557  0.806417  0.809961  0.808198  0.807636  \n",
       "20  0.737041  0.736829  0.737872  0.741279  0.728201  0.737425  0.738132  \n",
       "\n",
       "[19 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_performance_df = get_lr_performance_df(data_folder)\n",
    "lr_performance_df.to_csv(data_folder+\"lr_performance_df.csv\")\n",
    "joblib.dump(lr_performance_df, data_folder+\"lr_performance_df.pkl\")\n",
    "display(lr_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>l1_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>501.187234</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.501187</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.995262</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             c  l1_ratio\n",
       "1     3.981072      1.00\n",
       "2     0.031623      0.00\n",
       "3     0.063096      0.35\n",
       "5   501.187234      0.00\n",
       "6     0.031623      0.95\n",
       "7     0.501187      0.00\n",
       "8     0.063096      0.00\n",
       "9     0.031623      1.00\n",
       "10    0.063096      1.00\n",
       "11    1.995262      1.00\n",
       "12    0.015849      0.10\n",
       "13    0.015849      0.10\n",
       "14    0.063096      0.75\n",
       "15    1.000000      1.00\n",
       "16    0.001995      0.65\n",
       "17    0.063096      0.00\n",
       "18    0.031623      1.00\n",
       "19    0.031623      0.20\n",
       "20    0.251189      0.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_hyperparams_df = get_lr_hyperparams_df(data_folder)\n",
    "joblib.dump(lr_hyperparams_df, data_folder + \"lr_hyperparams_df.pkl\")\n",
    "lr_hyperparams_df.to_csv(data_folder + \"lr_hyperparams_df.csv\")\n",
    "display(lr_hyperparams_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    XGBoost\n",
    "        No HyperParameterOptimisation\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data_folder = \"/data/pereirabarataap/EVOA_revisited/\"\n",
    "df = joblib.load(data_folder + \"waste_df.pkl\")\n",
    "labels = sorted(df[\"code\"].unique(), key=lambda x: int(x))\n",
    "labels.remove(\"4\") # unable to cv model on 8 istances.\n",
    "k = 10 # k-folds\n",
    "all_folds, fold_ids = get_all_folds_ids(df, k)\n",
    "outer_fold_ids = [fold_id for fold_id in fold_ids if (len(fold_id)==1)]\n",
    "clf_template = XGBC(random_state=42, n_jobs=-1, objective=\"binary:logitraw\")\n",
    "label_cv_dfs = Parallel(n_jobs=-1, backend=\"loky\", temp_folder=data_folder)(\n",
    "    delayed(get_label_cv_dfs)(copy(i), copy(labels), copy(outer_fold_ids), copy(data_folder), copy(clf_template)) for i in range(len(labels))\n",
    ")\n",
    "xgb_performance_df = get_cv_df(label_cv_dfs)\n",
    "xgb_performance_df.to_csv(data_folder + \"xgb_performance_df.csv\")\n",
    "joblib.dump(xgb_performance_df, data_folder + \"xgb_performance_df.pkl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_stdv</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_stdv</th>\n",
       "      <th>0_test</th>\n",
       "      <th>1_test</th>\n",
       "      <th>2_test</th>\n",
       "      <th>3_test</th>\n",
       "      <th>4_test</th>\n",
       "      <th>5_test</th>\n",
       "      <th>...</th>\n",
       "      <th>0_train</th>\n",
       "      <th>1_train</th>\n",
       "      <th>2_train</th>\n",
       "      <th>3_train</th>\n",
       "      <th>4_train</th>\n",
       "      <th>5_train</th>\n",
       "      <th>6_train</th>\n",
       "      <th>7_train</th>\n",
       "      <th>8_train</th>\n",
       "      <th>9_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.985020</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.983843</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.980349</td>\n",
       "      <td>0.987773</td>\n",
       "      <td>0.983843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.918864</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>0.988863</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.906755</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>0.953670</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.902795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.987927</td>\n",
       "      <td>0.992937</td>\n",
       "      <td>0.987795</td>\n",
       "      <td>0.990635</td>\n",
       "      <td>0.988762</td>\n",
       "      <td>0.986849</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.989499</td>\n",
       "      <td>0.985498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.907857</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>0.972745</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.901951</td>\n",
       "      <td>0.926422</td>\n",
       "      <td>0.934160</td>\n",
       "      <td>0.904464</td>\n",
       "      <td>0.865708</td>\n",
       "      <td>0.883532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972890</td>\n",
       "      <td>0.969319</td>\n",
       "      <td>0.971656</td>\n",
       "      <td>0.974486</td>\n",
       "      <td>0.973743</td>\n",
       "      <td>0.974503</td>\n",
       "      <td>0.973631</td>\n",
       "      <td>0.973463</td>\n",
       "      <td>0.971192</td>\n",
       "      <td>0.972569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.755163</td>\n",
       "      <td>0.082310</td>\n",
       "      <td>0.985991</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.748518</td>\n",
       "      <td>0.744787</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.837687</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.699123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987661</td>\n",
       "      <td>0.982820</td>\n",
       "      <td>0.985049</td>\n",
       "      <td>0.978960</td>\n",
       "      <td>0.987718</td>\n",
       "      <td>0.990020</td>\n",
       "      <td>0.986863</td>\n",
       "      <td>0.989792</td>\n",
       "      <td>0.986782</td>\n",
       "      <td>0.984249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.859756</td>\n",
       "      <td>0.768136</td>\n",
       "      <td>0.800460</td>\n",
       "      <td>0.740732</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.763031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929667</td>\n",
       "      <td>0.927865</td>\n",
       "      <td>0.931637</td>\n",
       "      <td>0.927376</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.927146</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.931575</td>\n",
       "      <td>0.934470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.874449</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.836050</td>\n",
       "      <td>0.794486</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.836941</td>\n",
       "      <td>0.831090</td>\n",
       "      <td>0.820765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875376</td>\n",
       "      <td>0.876618</td>\n",
       "      <td>0.872199</td>\n",
       "      <td>0.868917</td>\n",
       "      <td>0.875176</td>\n",
       "      <td>0.875955</td>\n",
       "      <td>0.872225</td>\n",
       "      <td>0.877260</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.874534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.855895</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.947046</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.840107</td>\n",
       "      <td>0.867144</td>\n",
       "      <td>0.879742</td>\n",
       "      <td>0.822651</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>0.824101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944484</td>\n",
       "      <td>0.947007</td>\n",
       "      <td>0.950195</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.946270</td>\n",
       "      <td>0.949387</td>\n",
       "      <td>0.943699</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>0.945779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>0.980646</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.885136</td>\n",
       "      <td>0.971002</td>\n",
       "      <td>0.961189</td>\n",
       "      <td>0.926772</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.920668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981239</td>\n",
       "      <td>0.979206</td>\n",
       "      <td>0.979318</td>\n",
       "      <td>0.980557</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.981695</td>\n",
       "      <td>0.982602</td>\n",
       "      <td>0.977615</td>\n",
       "      <td>0.981159</td>\n",
       "      <td>0.983237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.788352</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.909523</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.746651</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.810562</td>\n",
       "      <td>0.732453</td>\n",
       "      <td>0.770307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913685</td>\n",
       "      <td>0.908195</td>\n",
       "      <td>0.905675</td>\n",
       "      <td>0.907675</td>\n",
       "      <td>0.916336</td>\n",
       "      <td>0.914878</td>\n",
       "      <td>0.906530</td>\n",
       "      <td>0.904969</td>\n",
       "      <td>0.904730</td>\n",
       "      <td>0.912552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.895930</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>0.942169</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.878416</td>\n",
       "      <td>0.881297</td>\n",
       "      <td>0.873017</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>0.921914</td>\n",
       "      <td>0.907175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941535</td>\n",
       "      <td>0.946147</td>\n",
       "      <td>0.940836</td>\n",
       "      <td>0.940884</td>\n",
       "      <td>0.942103</td>\n",
       "      <td>0.940821</td>\n",
       "      <td>0.943720</td>\n",
       "      <td>0.942111</td>\n",
       "      <td>0.942411</td>\n",
       "      <td>0.941128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.913038</td>\n",
       "      <td>0.908357</td>\n",
       "      <td>0.946005</td>\n",
       "      <td>0.868617</td>\n",
       "      <td>0.906191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971473</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.971028</td>\n",
       "      <td>0.974246</td>\n",
       "      <td>0.973406</td>\n",
       "      <td>0.975643</td>\n",
       "      <td>0.971053</td>\n",
       "      <td>0.973377</td>\n",
       "      <td>0.972328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.719550</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>0.925180</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.623573</td>\n",
       "      <td>0.616865</td>\n",
       "      <td>0.800603</td>\n",
       "      <td>0.672635</td>\n",
       "      <td>0.753383</td>\n",
       "      <td>0.725839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930747</td>\n",
       "      <td>0.916663</td>\n",
       "      <td>0.919662</td>\n",
       "      <td>0.926566</td>\n",
       "      <td>0.928714</td>\n",
       "      <td>0.924834</td>\n",
       "      <td>0.929347</td>\n",
       "      <td>0.925537</td>\n",
       "      <td>0.927370</td>\n",
       "      <td>0.922357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.024411</td>\n",
       "      <td>0.917787</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.821645</td>\n",
       "      <td>0.839121</td>\n",
       "      <td>0.827220</td>\n",
       "      <td>0.778203</td>\n",
       "      <td>0.788054</td>\n",
       "      <td>0.834096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922003</td>\n",
       "      <td>0.912990</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>0.914993</td>\n",
       "      <td>0.922726</td>\n",
       "      <td>0.914082</td>\n",
       "      <td>0.917059</td>\n",
       "      <td>0.915902</td>\n",
       "      <td>0.923586</td>\n",
       "      <td>0.913962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.922418</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.876788</td>\n",
       "      <td>0.858990</td>\n",
       "      <td>0.879710</td>\n",
       "      <td>0.899967</td>\n",
       "      <td>0.875513</td>\n",
       "      <td>0.881029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.924314</td>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.921800</td>\n",
       "      <td>0.919845</td>\n",
       "      <td>0.921013</td>\n",
       "      <td>0.923325</td>\n",
       "      <td>0.925963</td>\n",
       "      <td>0.917349</td>\n",
       "      <td>0.922894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.752642</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.835458</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.729684</td>\n",
       "      <td>0.744228</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>0.789837</td>\n",
       "      <td>0.747116</td>\n",
       "      <td>0.738313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835680</td>\n",
       "      <td>0.837829</td>\n",
       "      <td>0.837890</td>\n",
       "      <td>0.833062</td>\n",
       "      <td>0.835479</td>\n",
       "      <td>0.838018</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>0.836832</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.832973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.889035</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.941063</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.909179</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.880491</td>\n",
       "      <td>0.929486</td>\n",
       "      <td>0.890753</td>\n",
       "      <td>0.896159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.939431</td>\n",
       "      <td>0.943189</td>\n",
       "      <td>0.942413</td>\n",
       "      <td>0.937109</td>\n",
       "      <td>0.941437</td>\n",
       "      <td>0.941757</td>\n",
       "      <td>0.940307</td>\n",
       "      <td>0.939813</td>\n",
       "      <td>0.945591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.920996</td>\n",
       "      <td>0.015096</td>\n",
       "      <td>0.981531</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.949193</td>\n",
       "      <td>0.930064</td>\n",
       "      <td>0.912766</td>\n",
       "      <td>0.918227</td>\n",
       "      <td>0.909849</td>\n",
       "      <td>0.929996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981939</td>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.982860</td>\n",
       "      <td>0.982925</td>\n",
       "      <td>0.981596</td>\n",
       "      <td>0.979264</td>\n",
       "      <td>0.981102</td>\n",
       "      <td>0.982577</td>\n",
       "      <td>0.983384</td>\n",
       "      <td>0.981466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.851244</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.878184</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.831022</td>\n",
       "      <td>0.853574</td>\n",
       "      <td>0.863370</td>\n",
       "      <td>0.849830</td>\n",
       "      <td>0.831637</td>\n",
       "      <td>0.836918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880097</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>0.875317</td>\n",
       "      <td>0.877129</td>\n",
       "      <td>0.881537</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>0.876676</td>\n",
       "      <td>0.877112</td>\n",
       "      <td>0.879774</td>\n",
       "      <td>0.877690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.779231</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.878861</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.787076</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.784702</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>0.757094</td>\n",
       "      <td>0.769914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882198</td>\n",
       "      <td>0.881833</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.882261</td>\n",
       "      <td>0.877635</td>\n",
       "      <td>0.881958</td>\n",
       "      <td>0.878159</td>\n",
       "      <td>0.875095</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.876549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_mean  test_stdv  train_mean  train_stdv    0_test    1_test  \\\n",
       "1    0.985020   0.010182    0.999950    0.000034  0.983843  0.999127   \n",
       "2    0.918864   0.036806    0.988863    0.001973  0.906755  0.955800   \n",
       "3    0.907857   0.027047    0.972745    0.001543  0.901951  0.926422   \n",
       "5    0.755163   0.082310    0.985991    0.003182  0.748518  0.744787   \n",
       "6    0.793728   0.037049    0.929513    0.003171  0.859756  0.768136   \n",
       "7    0.820620   0.015251    0.874449    0.002451  0.836050  0.794486   \n",
       "8    0.855895   0.024823    0.947046    0.002065  0.840107  0.867144   \n",
       "9    0.914839   0.046925    0.980646    0.001611  0.885136  0.971002   \n",
       "10   0.788352   0.034913    0.909523    0.004174  0.759300  0.746651   \n",
       "11   0.895930   0.016078    0.942169    0.001582  0.878416  0.881297   \n",
       "12   0.897473   0.031264    0.972693    0.001409  0.938068  0.913038   \n",
       "13   0.719550   0.062107    0.925180    0.004228  0.623573  0.616865   \n",
       "14   0.816915   0.024411    0.917787    0.003831  0.821645  0.839121   \n",
       "15   0.882872   0.015882    0.922418    0.002385  0.876788  0.858990   \n",
       "16   0.752642   0.018960    0.835458    0.002641  0.729684  0.744228   \n",
       "17   0.889035   0.022077    0.941063    0.002238  0.909179  0.866667   \n",
       "18   0.920996   0.015096    0.981531    0.001577  0.949193  0.930064   \n",
       "19   0.851244   0.013470    0.878184    0.001795  0.831022  0.853574   \n",
       "20   0.779231   0.027367    0.878861    0.002727  0.787076  0.770226   \n",
       "\n",
       "      2_test    3_test    4_test    5_test  ...   0_train   1_train   2_train  \\\n",
       "1   0.965066  0.980349  0.987773  0.983843  ...  0.999951  0.999898  1.000000   \n",
       "2   0.850563  0.953670  0.883462  0.902795  ...  0.988712  0.987927  0.992937   \n",
       "3   0.934160  0.904464  0.865708  0.883532  ...  0.972890  0.969319  0.971656   \n",
       "5   0.774912  0.837687  0.743108  0.699123  ...  0.987661  0.982820  0.985049   \n",
       "6   0.800460  0.740732  0.821526  0.763031  ...  0.929667  0.927865  0.931637   \n",
       "7   0.837349  0.836941  0.831090  0.820765  ...  0.875376  0.876618  0.872199   \n",
       "8   0.879742  0.822651  0.858090  0.824101  ...  0.944484  0.947007  0.950195   \n",
       "9   0.961189  0.926772  0.830502  0.920668  ...  0.981239  0.979206  0.979318   \n",
       "10  0.823349  0.810562  0.732453  0.770307  ...  0.913685  0.908195  0.905675   \n",
       "11  0.873017  0.898483  0.921914  0.907175  ...  0.941535  0.946147  0.940836   \n",
       "12  0.908357  0.946005  0.868617  0.906191  ...  0.971473  0.972478  0.971893   \n",
       "13  0.800603  0.672635  0.753383  0.725839  ...  0.930747  0.916663  0.919662   \n",
       "14  0.827220  0.778203  0.788054  0.834096  ...  0.922003  0.912990  0.920568   \n",
       "15  0.879710  0.899967  0.875513  0.881029  ...  0.923137  0.924314  0.924540   \n",
       "16  0.749415  0.789837  0.747116  0.738313  ...  0.835680  0.837829  0.837890   \n",
       "17  0.880491  0.929486  0.890753  0.896159  ...  0.939587  0.939431  0.943189   \n",
       "18  0.912766  0.918227  0.909849  0.929996  ...  0.981939  0.978193  0.982860   \n",
       "19  0.863370  0.849830  0.831637  0.836918  ...  0.880097  0.877304  0.875317   \n",
       "20  0.784702  0.767000  0.757094  0.769914  ...  0.882198  0.881833  0.876172   \n",
       "\n",
       "     3_train   4_train   5_train   6_train   7_train   8_train   9_train  \n",
       "1   0.999917  0.999942  0.999956  0.999903  0.999995  0.999954  0.999985  \n",
       "2   0.987795  0.990635  0.988762  0.986849  0.990017  0.989499  0.985498  \n",
       "3   0.974486  0.973743  0.974503  0.973631  0.973463  0.971192  0.972569  \n",
       "5   0.978960  0.987718  0.990020  0.986863  0.989792  0.986782  0.984249  \n",
       "6   0.927376  0.933591  0.923497  0.927146  0.928302  0.931575  0.934470  \n",
       "7   0.868917  0.875176  0.875955  0.872225  0.877260  0.876234  0.874534  \n",
       "8   0.948354  0.946270  0.949387  0.943699  0.946088  0.949200  0.945779  \n",
       "9   0.980557  0.979832  0.981695  0.982602  0.977615  0.981159  0.983237  \n",
       "10  0.907675  0.916336  0.914878  0.906530  0.904969  0.904730  0.912552  \n",
       "11  0.940884  0.942103  0.940821  0.943720  0.942111  0.942411  0.941128  \n",
       "12  0.971028  0.974246  0.973406  0.975643  0.971053  0.973377  0.972328  \n",
       "13  0.926566  0.928714  0.924834  0.929347  0.925537  0.927370  0.922357  \n",
       "14  0.914993  0.922726  0.914082  0.917059  0.915902  0.923586  0.913962  \n",
       "15  0.921800  0.919845  0.921013  0.923325  0.925963  0.917349  0.922894  \n",
       "16  0.833062  0.835479  0.838018  0.837245  0.836832  0.829575  0.832973  \n",
       "17  0.942413  0.937109  0.941437  0.941757  0.940307  0.939813  0.945591  \n",
       "18  0.982925  0.981596  0.979264  0.981102  0.982577  0.983384  0.981466  \n",
       "19  0.877129  0.881537  0.879200  0.876676  0.877112  0.879774  0.877690  \n",
       "20  0.882261  0.877635  0.881958  0.878159  0.875095  0.876745  0.876549  \n",
       "\n",
       "[19 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xgb_performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">lr</th>\n",
       "      <th>test_tt_pval</th>\n",
       "      <th>train_tt_pval</th>\n",
       "      <th colspan=\"5\" halign=\"left\">xgb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_stdv</th>\n",
       "      <th>tt_pval</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_stdv</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_stdv</th>\n",
       "      <th>tt_pval</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.982791</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.988298</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>7.091750e-01</td>\n",
       "      <td>1.462717e-04</td>\n",
       "      <td>0.985020</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>1.722525e-03</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.868437</td>\n",
       "      <td>0.043846</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.907673</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>1.305311e-03</td>\n",
       "      <td>3.443557e-11</td>\n",
       "      <td>0.918864</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>2.891079e-04</td>\n",
       "      <td>0.988863</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.868277</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>0.884360</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>3.259480e-04</td>\n",
       "      <td>2.069456e-13</td>\n",
       "      <td>0.907857</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>4.993370e-05</td>\n",
       "      <td>0.972745</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672360</td>\n",
       "      <td>0.091644</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.820775</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>2.465799e-02</td>\n",
       "      <td>5.001084e-10</td>\n",
       "      <td>0.755163</td>\n",
       "      <td>0.082310</td>\n",
       "      <td>1.458600e-05</td>\n",
       "      <td>0.985991</td>\n",
       "      <td>0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.740365</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.284007</td>\n",
       "      <td>0.754964</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>7.062494e-03</td>\n",
       "      <td>1.118661e-12</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>1.477984e-06</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>0.003171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775782</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.150840</td>\n",
       "      <td>0.784155</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>4.022147e-06</td>\n",
       "      <td>5.329071e-15</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>1.653803e-06</td>\n",
       "      <td>0.874449</td>\n",
       "      <td>0.002451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>0.820357</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>1.750418e-05</td>\n",
       "      <td>3.290701e-13</td>\n",
       "      <td>0.855895</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>1.460983e-06</td>\n",
       "      <td>0.947046</td>\n",
       "      <td>0.002065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.046674</td>\n",
       "      <td>0.090957</td>\n",
       "      <td>0.897139</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>8.153591e-03</td>\n",
       "      <td>7.722963e-08</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>2.278846e-03</td>\n",
       "      <td>0.980646</td>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.736915</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.075393</td>\n",
       "      <td>0.758426</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>6.284830e-04</td>\n",
       "      <td>8.903989e-14</td>\n",
       "      <td>0.788352</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>2.174059e-06</td>\n",
       "      <td>0.909523</td>\n",
       "      <td>0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.814735</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.066580</td>\n",
       "      <td>0.829406</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>3.786363e-06</td>\n",
       "      <td>6.661338e-16</td>\n",
       "      <td>0.895930</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>1.107597e-05</td>\n",
       "      <td>0.942169</td>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.860228</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.887660</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>5.211710e-03</td>\n",
       "      <td>1.311884e-11</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>4.921378e-05</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.668044</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>1.552345e-04</td>\n",
       "      <td>2.078351e-10</td>\n",
       "      <td>0.719550</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>3.601541e-06</td>\n",
       "      <td>0.925180</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.776115</td>\n",
       "      <td>0.034193</td>\n",
       "      <td>0.208139</td>\n",
       "      <td>0.791715</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>1.677101e-03</td>\n",
       "      <td>4.022116e-12</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.024411</td>\n",
       "      <td>4.153465e-07</td>\n",
       "      <td>0.917787</td>\n",
       "      <td>0.003831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.840980</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.200723</td>\n",
       "      <td>0.849782</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>1.510826e-04</td>\n",
       "      <td>9.937828e-12</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>3.282153e-05</td>\n",
       "      <td>0.922418</td>\n",
       "      <td>0.002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.913445</td>\n",
       "      <td>0.695149</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.386166e-05</td>\n",
       "      <td>8.881784e-16</td>\n",
       "      <td>0.752642</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>2.724176e-07</td>\n",
       "      <td>0.835458</td>\n",
       "      <td>0.002641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>0.276987</td>\n",
       "      <td>0.854385</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>2.169136e-05</td>\n",
       "      <td>5.458967e-12</td>\n",
       "      <td>0.889035</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>5.500128e-05</td>\n",
       "      <td>0.941063</td>\n",
       "      <td>0.002238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.908823</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>4.505315e-03</td>\n",
       "      <td>7.536942e-10</td>\n",
       "      <td>0.920996</td>\n",
       "      <td>0.015096</td>\n",
       "      <td>6.502336e-07</td>\n",
       "      <td>0.981531</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.806364</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.614676</td>\n",
       "      <td>0.808896</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>6.593272e-07</td>\n",
       "      <td>2.664535e-15</td>\n",
       "      <td>0.851244</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>1.880292e-04</td>\n",
       "      <td>0.878184</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.719496</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.736445</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>6.998907e-07</td>\n",
       "      <td>1.043610e-14</td>\n",
       "      <td>0.779231</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>1.517268e-06</td>\n",
       "      <td>0.878861</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr                                            test_tt_pval  \\\n",
       "   test_mean test_stdv   tt_pval train_mean train_stdv                 \n",
       "1   0.982791  0.008034  0.086643   0.988298   0.003852  7.091750e-01   \n",
       "2   0.868437  0.043846  0.025173   0.907673   0.004792  1.305311e-03   \n",
       "3   0.868277  0.019864  0.038604   0.884360   0.002883  3.259480e-04   \n",
       "5   0.672360  0.091644  0.000864   0.820775   0.011965  2.465799e-02   \n",
       "6   0.740365  0.038190  0.284007   0.754964   0.005085  7.062494e-03   \n",
       "7   0.775782  0.015962  0.150840   0.784155   0.001360  4.022147e-06   \n",
       "8   0.797800  0.026271  0.030398   0.820357   0.004259  1.750418e-05   \n",
       "9   0.867250  0.046674  0.090957   0.897139   0.010907  8.153591e-03   \n",
       "10  0.736915  0.031900  0.075393   0.758426   0.005239  6.284830e-04   \n",
       "11  0.814735  0.021021  0.066580   0.829406   0.002619  3.786363e-06   \n",
       "12  0.860228  0.031750  0.029401   0.887660   0.004043  5.211710e-03   \n",
       "13  0.608835  0.062540  0.020169   0.668044   0.016376  1.552345e-04   \n",
       "14  0.776115  0.034193  0.208139   0.791715   0.005597  1.677101e-03   \n",
       "15  0.840980  0.018926  0.200723   0.849782   0.003324  1.510826e-04   \n",
       "16  0.694534  0.016414  0.913445   0.695149   0.001801  2.386166e-05   \n",
       "17  0.845450  0.023057  0.276987   0.854385   0.002597  2.169136e-05   \n",
       "18  0.893555  0.014946  0.014707   0.908823   0.005660  4.505315e-03   \n",
       "19  0.806364  0.014495  0.614676   0.808896   0.001593  6.593272e-07   \n",
       "20  0.719496  0.023773  0.062127   0.736445   0.003396  6.998907e-07   \n",
       "\n",
       "   train_tt_pval       xgb                                                \n",
       "                 test_mean test_stdv       tt_pval train_mean train_stdv  \n",
       "1   1.462717e-04  0.985020  0.010182  1.722525e-03   0.999950   0.000034  \n",
       "2   3.443557e-11  0.918864  0.036806  2.891079e-04   0.988863   0.001973  \n",
       "3   2.069456e-13  0.907857  0.027047  4.993370e-05   0.972745   0.001543  \n",
       "5   5.001084e-10  0.755163  0.082310  1.458600e-05   0.985991   0.003182  \n",
       "6   1.118661e-12  0.793728  0.037049  1.477984e-06   0.929513   0.003171  \n",
       "7   5.329071e-15  0.820620  0.015251  1.653803e-06   0.874449   0.002451  \n",
       "8   3.290701e-13  0.855895  0.024823  1.460983e-06   0.947046   0.002065  \n",
       "9   7.722963e-08  0.914839  0.046925  2.278846e-03   0.980646   0.001611  \n",
       "10  8.903989e-14  0.788352  0.034913  2.174059e-06   0.909523   0.004174  \n",
       "11  6.661338e-16  0.895930  0.016078  1.107597e-05   0.942169   0.001582  \n",
       "12  1.311884e-11  0.897473  0.031264  4.921378e-05   0.972693   0.001409  \n",
       "13  2.078351e-10  0.719550  0.062107  3.601541e-06   0.925180   0.004228  \n",
       "14  4.022116e-12  0.816915  0.024411  4.153465e-07   0.917787   0.003831  \n",
       "15  9.937828e-12  0.882872  0.015882  3.282153e-05   0.922418   0.002385  \n",
       "16  8.881784e-16  0.752642  0.018960  2.724176e-07   0.835458   0.002641  \n",
       "17  5.458967e-12  0.889035  0.022077  5.500128e-05   0.941063   0.002238  \n",
       "18  7.536942e-10  0.920996  0.015096  6.502336e-07   0.981531   0.001577  \n",
       "19  2.664535e-15  0.851244  0.013470  1.880292e-04   0.878184   0.001795  \n",
       "20  1.043610e-14  0.779231  0.027367  1.517268e-06   0.878861   0.002727  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tt_compare_df = get_tt_compare_df(data_folder, \"lr_performance_df\", \"xgb_performance_df\")\n",
    "tt_compare_df.to_csv(data_folder + \"tt_compare_df.csv\")\n",
    "joblib.dump(tt_compare_df, data_folder + \"tt_compare_df.pkl\")\n",
    "display(tt_compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores dataframe\n",
    "#### This is the scoring system used to produce our projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = get_scores_df(data_folder)\n",
    "scores_df.to_csv(data_folder + \"scores_df.csv\")\n",
    "joblib.dump(scores_df, data_folder + \"scores_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>1_lr</th>\n",
       "      <th>1_xgb</th>\n",
       "      <th>2_lr</th>\n",
       "      <th>2_xgb</th>\n",
       "      <th>3_lr</th>\n",
       "      <th>3_xgb</th>\n",
       "      <th>5_lr</th>\n",
       "      <th>5_xgb</th>\n",
       "      <th>6_lr</th>\n",
       "      <th>...</th>\n",
       "      <th>16_lr</th>\n",
       "      <th>16_xgb</th>\n",
       "      <th>17_lr</th>\n",
       "      <th>17_xgb</th>\n",
       "      <th>18_lr</th>\n",
       "      <th>18_xgb</th>\n",
       "      <th>19_lr</th>\n",
       "      <th>19_xgb</th>\n",
       "      <th>20_lr</th>\n",
       "      <th>20_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0293772</td>\n",
       "      <td>0.00782851</td>\n",
       "      <td>0.0365902</td>\n",
       "      <td>0.0997355</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>0.513421</td>\n",
       "      <td>0.513354</td>\n",
       "      <td>0.530205</td>\n",
       "      <td>0.456974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534771</td>\n",
       "      <td>0.51488</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>0.871418</td>\n",
       "      <td>0.0283062</td>\n",
       "      <td>0.0902198</td>\n",
       "      <td>0.695996</td>\n",
       "      <td>0.766852</td>\n",
       "      <td>0.17982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00402367</td>\n",
       "      <td>0.0228984</td>\n",
       "      <td>0.0351208</td>\n",
       "      <td>0.209359</td>\n",
       "      <td>0.225676</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.500105</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535804</td>\n",
       "      <td>0.405696</td>\n",
       "      <td>0.3647</td>\n",
       "      <td>0.284606</td>\n",
       "      <td>0.844235</td>\n",
       "      <td>0.410807</td>\n",
       "      <td>0.0760985</td>\n",
       "      <td>0.15266</td>\n",
       "      <td>0.749594</td>\n",
       "      <td>0.407264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0297643</td>\n",
       "      <td>0.00360807</td>\n",
       "      <td>0.03559</td>\n",
       "      <td>0.145083</td>\n",
       "      <td>0.248423</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.313739</td>\n",
       "      <td>0.581658</td>\n",
       "      <td>0.387586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536833</td>\n",
       "      <td>0.433435</td>\n",
       "      <td>0.334795</td>\n",
       "      <td>0.264268</td>\n",
       "      <td>0.848919</td>\n",
       "      <td>0.547685</td>\n",
       "      <td>0.0868955</td>\n",
       "      <td>0.0986178</td>\n",
       "      <td>0.760938</td>\n",
       "      <td>0.84356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5.14411e-05</td>\n",
       "      <td>0.0221738</td>\n",
       "      <td>0.391876</td>\n",
       "      <td>0.356359</td>\n",
       "      <td>0.402547</td>\n",
       "      <td>0.0269358</td>\n",
       "      <td>0.893502</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>0.283151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530927</td>\n",
       "      <td>0.515776</td>\n",
       "      <td>0.519692</td>\n",
       "      <td>0.913777</td>\n",
       "      <td>0.585303</td>\n",
       "      <td>0.436097</td>\n",
       "      <td>0.191945</td>\n",
       "      <td>0.191831</td>\n",
       "      <td>0.510811</td>\n",
       "      <td>0.589317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0323283</td>\n",
       "      <td>0.0116844</td>\n",
       "      <td>0.0191406</td>\n",
       "      <td>0.093309</td>\n",
       "      <td>0.185063</td>\n",
       "      <td>0.0791544</td>\n",
       "      <td>0.658697</td>\n",
       "      <td>0.596678</td>\n",
       "      <td>0.446205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53241</td>\n",
       "      <td>0.645512</td>\n",
       "      <td>0.424293</td>\n",
       "      <td>0.539632</td>\n",
       "      <td>0.849177</td>\n",
       "      <td>0.145554</td>\n",
       "      <td>0.0827873</td>\n",
       "      <td>0.342109</td>\n",
       "      <td>0.776595</td>\n",
       "      <td>0.253364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11465</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00330456</td>\n",
       "      <td>0.0168313</td>\n",
       "      <td>0.681804</td>\n",
       "      <td>0.711876</td>\n",
       "      <td>0.540933</td>\n",
       "      <td>0.837078</td>\n",
       "      <td>0.246553</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.282123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404851</td>\n",
       "      <td>0.292744</td>\n",
       "      <td>0.582041</td>\n",
       "      <td>0.219627</td>\n",
       "      <td>0.00780976</td>\n",
       "      <td>0.0174318</td>\n",
       "      <td>0.740295</td>\n",
       "      <td>0.810871</td>\n",
       "      <td>0.303669</td>\n",
       "      <td>0.163423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11466</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000169039</td>\n",
       "      <td>0.00836709</td>\n",
       "      <td>0.475004</td>\n",
       "      <td>0.354021</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>0.684576</td>\n",
       "      <td>0.0425276</td>\n",
       "      <td>0.155449</td>\n",
       "      <td>0.01958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481697</td>\n",
       "      <td>0.102153</td>\n",
       "      <td>0.655635</td>\n",
       "      <td>0.279063</td>\n",
       "      <td>0.164303</td>\n",
       "      <td>0.0169841</td>\n",
       "      <td>0.783334</td>\n",
       "      <td>0.835407</td>\n",
       "      <td>0.745917</td>\n",
       "      <td>0.18973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11467</td>\n",
       "      <td>16</td>\n",
       "      <td>4.49184e-06</td>\n",
       "      <td>0.0298767</td>\n",
       "      <td>0.736987</td>\n",
       "      <td>0.459301</td>\n",
       "      <td>0.585829</td>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.555869</td>\n",
       "      <td>0.738742</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407628</td>\n",
       "      <td>0.483905</td>\n",
       "      <td>0.603705</td>\n",
       "      <td>0.849367</td>\n",
       "      <td>0.00301356</td>\n",
       "      <td>0.170098</td>\n",
       "      <td>0.745181</td>\n",
       "      <td>0.491628</td>\n",
       "      <td>0.300511</td>\n",
       "      <td>0.310641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11468</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0296298</td>\n",
       "      <td>0.00608764</td>\n",
       "      <td>0.437828</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.382737</td>\n",
       "      <td>0.394955</td>\n",
       "      <td>0.0729643</td>\n",
       "      <td>0.323185</td>\n",
       "      <td>0.0185423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.171336</td>\n",
       "      <td>0.712402</td>\n",
       "      <td>0.512515</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>0.0422402</td>\n",
       "      <td>0.794501</td>\n",
       "      <td>0.81838</td>\n",
       "      <td>0.778714</td>\n",
       "      <td>0.200264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11469</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000973017</td>\n",
       "      <td>0.00520904</td>\n",
       "      <td>0.679135</td>\n",
       "      <td>0.107747</td>\n",
       "      <td>0.566157</td>\n",
       "      <td>0.26439</td>\n",
       "      <td>0.433691</td>\n",
       "      <td>0.922507</td>\n",
       "      <td>0.207441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402238</td>\n",
       "      <td>0.434047</td>\n",
       "      <td>0.584311</td>\n",
       "      <td>0.43493</td>\n",
       "      <td>0.00316498</td>\n",
       "      <td>0.369364</td>\n",
       "      <td>0.745629</td>\n",
       "      <td>0.196653</td>\n",
       "      <td>0.270642</td>\n",
       "      <td>0.514085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11470 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code         1_lr       1_xgb       2_lr      2_xgb      3_lr  \\\n",
       "0       16    0.0293772  0.00782851  0.0365902  0.0997355  0.198082   \n",
       "1       15   0.00402367   0.0228984  0.0351208   0.209359  0.225676   \n",
       "2       20    0.0297643  0.00360807    0.03559   0.145083  0.248423   \n",
       "3        8  5.14411e-05   0.0221738   0.391876   0.356359  0.402547   \n",
       "4       17    0.0323283   0.0116844  0.0191406   0.093309  0.185063   \n",
       "...    ...          ...         ...        ...        ...       ...   \n",
       "11465   19   0.00330456   0.0168313   0.681804   0.711876  0.540933   \n",
       "11466   19  0.000169039  0.00836709   0.475004   0.354021  0.316642   \n",
       "11467   16  4.49184e-06   0.0298767   0.736987   0.459301  0.585829   \n",
       "11468    7    0.0296298  0.00608764   0.437828   0.719449  0.382737   \n",
       "11469   20  0.000973017  0.00520904   0.679135   0.107747  0.566157   \n",
       "\n",
       "           3_xgb       5_lr     5_xgb       6_lr  ...     16_lr    16_xgb  \\\n",
       "0       0.513421   0.513354  0.530205   0.456974  ...  0.534771   0.51488   \n",
       "1       0.016143     0.5433  0.500105   0.443114  ...  0.535804  0.405696   \n",
       "2       0.169697   0.313739  0.581658   0.387586  ...  0.536833  0.433435   \n",
       "3      0.0269358   0.893502  0.556622   0.283151  ...  0.530927  0.515776   \n",
       "4      0.0791544   0.658697  0.596678   0.446205  ...   0.53241  0.645512   \n",
       "...          ...        ...       ...        ...  ...       ...       ...   \n",
       "11465   0.837078   0.246553  0.200013   0.282123  ...  0.404851  0.292744   \n",
       "11466   0.684576  0.0425276  0.155449    0.01958  ...  0.481697  0.102153   \n",
       "11467   0.606125   0.555869  0.738742   0.236266  ...  0.407628  0.483905   \n",
       "11468   0.394955  0.0729643  0.323185  0.0185423  ...  0.478843  0.171336   \n",
       "11469    0.26439   0.433691  0.922507   0.207441  ...  0.402238  0.434047   \n",
       "\n",
       "          17_lr    17_xgb       18_lr     18_xgb      19_lr     19_xgb  \\\n",
       "0      0.325687  0.748771    0.871418  0.0283062  0.0902198   0.695996   \n",
       "1        0.3647  0.284606    0.844235   0.410807  0.0760985    0.15266   \n",
       "2      0.334795  0.264268    0.848919   0.547685  0.0868955  0.0986178   \n",
       "3      0.519692  0.913777    0.585303   0.436097   0.191945   0.191831   \n",
       "4      0.424293  0.539632    0.849177   0.145554  0.0827873   0.342109   \n",
       "...         ...       ...         ...        ...        ...        ...   \n",
       "11465  0.582041  0.219627  0.00780976  0.0174318   0.740295   0.810871   \n",
       "11466  0.655635  0.279063    0.164303  0.0169841   0.783334   0.835407   \n",
       "11467  0.603705  0.849367  0.00301356   0.170098   0.745181   0.491628   \n",
       "11468  0.712402  0.512515    0.120545  0.0422402   0.794501    0.81838   \n",
       "11469  0.584311   0.43493  0.00316498   0.369364   0.745629   0.196653   \n",
       "\n",
       "          20_lr    20_xgb  \n",
       "0      0.766852   0.17982  \n",
       "1      0.749594  0.407264  \n",
       "2      0.760938   0.84356  \n",
       "3      0.510811  0.589317  \n",
       "4      0.776595  0.253364  \n",
       "...         ...       ...  \n",
       "11465  0.303669  0.163423  \n",
       "11466  0.745917   0.18973  \n",
       "11467  0.300511  0.310641  \n",
       "11468  0.778714  0.200264  \n",
       "11469  0.270642  0.514085  \n",
       "\n",
       "[11470 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = joblib.load(data_folder + \"scores_df.pkl\")\n",
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "### These projections are made using scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data_folder = \"/data/pereirabarataap/EVOA_revisited/\"\n",
    "scores_df = joblib.load(data_folder + \"scores_df.pkl\")\n",
    "tt_compare_df = joblib.load(data_folder + \"tt_compare_df.pkl\")\n",
    "labels = sorted(scores_df[\"code\"].unique().tolist(), key=lambda x: int(x))\n",
    "labels.remove(\"4\")\n",
    "for label in labels:\n",
    "    clf_columns = [label + \"_lr\", label + \"_xgb\"]\n",
    "    fig, axs = plt.subplots(1,2,figsize=(7, 3), dpi=600)\n",
    "    plt.subplots_adjust(wspace = 0.05)\n",
    "    feat_offset = 0.4\n",
    "    n_y0 = sum(scores_df[\"code\"]!=label)\n",
    "    n_y1 = sum(scores_df[\"code\"]==label)\n",
    "    y0 = MMS(feature_range=(1-feat_offset ,1+feat_offset)).fit_transform(np.random.normal(0,1,n_y0).reshape(-1,1))\n",
    "    y1 = MMS(feature_range=(0-feat_offset ,0+feat_offset)).fit_transform(np.random.normal(0,1,n_y1).reshape(-1,1)),\n",
    "    for i in range(len(axs)):\n",
    "        clf_column = clf_columns[i]\n",
    "        ax = axs[i]\n",
    "        x0 = scores_df.loc[scores_df[\"code\"]!=label, clf_column]\n",
    "        x1 = scores_df.loc[scores_df[\"code\"]==label, clf_column]\n",
    "        ax.scatter(\n",
    "            x=x0,\n",
    "            y=y0,\n",
    "            linewidth=0.5,\n",
    "            edgecolor=\"k\",\n",
    "            alpha=0.1,\n",
    "            s=10,\n",
    "            c=\"C3\",    \n",
    "            zorder=0\n",
    "        )\n",
    "        if len(x1) < 200:\n",
    "            x1_alpha = 0.75\n",
    "        elif len(x1) < 400:\n",
    "            x1_alpha = 0.5\n",
    "        else:\n",
    "            x1_alpha = 0.25\n",
    "        ax.scatter(\n",
    "            x=x1,\n",
    "            y=y1,\n",
    "            linewidth=0.5,\n",
    "            edgecolor=\"k\",\n",
    "            alpha=x1_alpha,\n",
    "            s=10,\n",
    "            c=\"C0\",\n",
    "            zorder=0\n",
    "        )\n",
    "        kde_x = np.linspace(0, 1, 1000)\n",
    "\n",
    "        kde = scipy.stats.gaussian_kde(x0.values.tolist())\n",
    "        kde_y0 = kde.pdf(kde_x)\n",
    "        kde_y0 = MMS(feature_range=(1-feat_offset-0.05 ,1+feat_offset+0.05)).fit_transform((kde_y0).reshape(-1,1))\n",
    "        ax.plot(kde_x, kde_y0, color=\"C3\", zorder=2, lw=1, alpha=0.5)\n",
    "        ax.fill_between(kde_x, min(kde_y0), kde_y0.ravel(), color=\"C3\", step=\"mid\", alpha=0.25, zorder=1)\n",
    "        \n",
    "        kde = scipy.stats.gaussian_kde(x1.values.tolist())\n",
    "        kde_y1 = kde.pdf(kde_x)\n",
    "        kde_y1 = MMS(feature_range=(0-feat_offset-0.05 ,0+feat_offset+0.05)).fit_transform(kde_y1.reshape(-1,1))\n",
    "        ax.plot(kde_x, kde_y1, color=\"C0\", zorder=2, lw=1, alpha=0.5)\n",
    "        ax.fill_between(kde_x, min(kde_y1), kde_y1.ravel(), color=\"C0\",step=\"mid\", alpha=0.25, zorder=1)\n",
    "        \n",
    "        if i==0:\n",
    "            roc_auc = round(tt_compare_df.loc[label, (\"lr\",\"test_mean\")], 4)\n",
    "        else:\n",
    "            roc_auc = round(tt_compare_df.loc[label, (\"xgb\",\"test_mean\")], 4)\n",
    "        \n",
    "        ax.set_title(\"LoW: \" + label + \"\\nROC AUC: \"+str(roc_auc), fontsize=7)\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "\n",
    "\n",
    "        xmin = -0.025\n",
    "        xmax = 1.025\n",
    "        ax.vlines(x=0.5, ymin=-0.5, ymax=1.5, ls=\"--\", alpha=0.5, linewidths=[0.25], colors=[\"k\"], zorder=0)\n",
    "        ax.hlines(y=0.5, xmin=xmin, xmax=xmax, alpha=.75, colors=[\"k\"], linewidths=[.5], linestyles=\"-.\", zorder=7)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim(-0.5, 1.5)\n",
    "    \n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(5)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
